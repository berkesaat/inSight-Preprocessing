{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from scipy import signal\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import numpy.random as npr\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data, axis=0)\n",
    "    return y\n",
    "\n",
    "def marker_fix(markers,frame_rate):\n",
    "    out=[]\n",
    "    for i in range(len(markers)-1):\n",
    "        chunk=[markers[i]]\n",
    "        chunk += [int(markers[i]*(1-a/frame_rate)+markers[i+1]*a/frame_rate) for a in range(1,frame_rate)]\n",
    "        out+=chunk\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example folderof files and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"partialdata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_without_F = ['P7', 'P4', 'Cz', 'Pz', 'P3', 'P8', 'O1', 'O2', 'T8', 'C4',\n",
    "                             'C3', 'T7', 'Oz', 'PO4',\n",
    "                              'CP6', 'CP2', 'CP1', 'CP5', 'PO3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_without_FandT = ['P7', 'P4', 'Cz', 'Pz', 'P3', 'P8', 'O1', 'O2', 'C4',\n",
    "                             'C3', 'Oz', 'PO4',\n",
    "                              'CP6', 'CP2', 'CP1', 'CP5', 'PO3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELS = ['P7', 'P4', 'Cz', 'Pz', 'P3', 'P8', 'O1', 'O2', 'T8', 'F8', 'C4',\n",
    "                             'F4', 'Fp2', 'Fz', 'C3', 'F3', 'Fp1', 'T7', 'F7', 'Oz', 'PO4', 'FC6',\n",
    "                             'FC2', 'AF4', 'CP6', 'CP2', 'CP1', 'CP5', 'FC1', 'FC5', 'AF3', 'PO3']\n",
    "def load_data(folder_path, channels = CHANNELS, shift = 50, lf=10, hf=100):\n",
    "    \n",
    "    # load the filenames in eeg_files\n",
    "    eeg_files = []\n",
    "    log_files = []\n",
    "    inf_files = []\n",
    "    for root, subdirs, files in os.walk(folder_path):\n",
    "        #print(files)\n",
    "        for f in files:\n",
    "            if f.endswith('.easy'):\n",
    "                eeg_files.append(os.path.join(root,f))\n",
    "            if f.endswith('.json'):\n",
    "                log_files.append(os.path.join(root,f))\n",
    "            if f.endswith('.info'):\n",
    "                inf_files.append(os.path.join(root,f))\n",
    "    print(f\"{len(eeg_files)} experiments selected.\")\n",
    "    # process channel indeces:\n",
    "    channel_idxs = [CHANNELS.index(ch) for ch in channels]\n",
    "\n",
    "    # load csv files into dataframes\n",
    "    outs = []\n",
    "    for i,file in enumerate(tqdm(eeg_files)):\n",
    "        # read the easy file with pandas #########################\n",
    "        df = pd.read_csv(file, \n",
    "                        delimiter = '\\t',\n",
    "                        engine = 'c',\n",
    "                        header = None,\n",
    "                        index_col=None)\n",
    "        \n",
    "        #process markers #########################################\n",
    "        raw_markers = df.loc[df[35]>0][35].values\n",
    "        raw_marker_idx = df.loc[df[35]>0][35].index.values\n",
    "        start_marker_loc = np.where(raw_markers==1)[0][-1]\n",
    "        start_marker_idx = raw_marker_idx[start_marker_loc]\n",
    "        end_marker_loc = np.where(raw_markers==1200)[0][-1]\n",
    "        end_marker_idx = raw_marker_idx[end_marker_loc]\n",
    "        raw_marker_idx = raw_marker_idx[start_marker_loc:end_marker_loc+1]\n",
    "\n",
    "        #marker indices after selecting the data_range\n",
    "        marker_idx = raw_marker_idx-start_marker_idx\n",
    "        out = {'markers':marker_idx}\n",
    "        # process EEG ############################################\n",
    "        # select the channels and shift and take the data between the begining and the end marker\n",
    "        raw_eeg = np.roll(np.array(df[channel_idxs]),\n",
    "                          shift=shift,axis=0)[start_marker_idx:end_marker_idx+1]\n",
    "\n",
    "        # read the sampling rate\n",
    "        with open(inf_files[i], 'r') as inf_file:\n",
    "            inf = inf_file.read()\n",
    "            inf_lines = inf.split('\\n')\n",
    "            sampling_rate = float(re.findall(\"\\d+\\.\\d+\", inf_lines[18])[0])\n",
    "        \n",
    "        # filter eeg\n",
    "        eeg = butter_bandpass_filter(raw_eeg,lf,hf,sampling_rate,order=5)\n",
    "        #eeg = RobustScaler(quantile_range=(25, 75)).fit_transform(eeg)\n",
    "        #\n",
    "        #eeg = QuantileTransformer(n_quantiles=1000,output_distribution='uniform').fit_transform(eeg)\n",
    "        out['eeg'] = eeg\n",
    "        # process embeddings ####################################\n",
    "        with open(log_files[i],'r') as log_file:\n",
    "            log = json.load(log_file)\n",
    "        out['embedding'] = np.array(log['e'])[:-20]\n",
    "        out['frame_rate'] = log['f']\n",
    "        out['video_length'] = log['vl']\n",
    "        out['truncation'] = log['t']\n",
    "        out['z_speed'] = log['z']\n",
    "        out['switch_len'] = log['sl'] \n",
    "        outs.append(out)\n",
    "    print('process completed!')\n",
    "    return outs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 experiments selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:14<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "data = load_data(test_path, channels=ch_without_FandT, shift=40, lf=5, hf=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling\n",
    "import pickle\n",
    "with open('prp_WFT_s60lf20hf80.pkl', 'wb') as pickle_out:  \n",
    "    pickle.dump(data, pickle_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prp_WFT_s60lf20hf80.pkl', 'rb') as pickle_in:  \n",
    "    data = pickle.load(pickle_in) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data to be used to make a pytorch data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, eeg_len, frames_len, overlap=0, condition=None, split=[0.8,0.2]):\n",
    "    if condition !=None:\n",
    "        check = True\n",
    "        prop,val = condition\n",
    "    else:\n",
    "        check = False\n",
    "\n",
    "    eeg_chunks = []\n",
    "    embedding_chunks = []\n",
    "    for d in tqdm(data):\n",
    "        if check:\n",
    "            if d[prop]!=val:\n",
    "                continue\n",
    "        d_len = d['eeg'].shape[0]\n",
    "        markers = d['markers']\n",
    "        all_frame_idx = marker_fix(markers,20)\n",
    "        eof = False\n",
    "        pointer = 0\n",
    "        while(not eof):\n",
    "            start = pointer\n",
    "            end = pointer + eeg_len\n",
    "            if end > d_len:\n",
    "                eof = True\n",
    "                continue\n",
    "            # append the EEG chunk    \n",
    "            eeg_chunk = d['eeg'][start:end]\n",
    "            eeg_chunks.append(eeg_chunk)\n",
    "\n",
    "            # append the embedding chunk \n",
    "            range_idx = np.arange(start,end+1)\n",
    "            frames_eeg_idx = np.intersect1d(all_frame_idx,range_idx)\n",
    "            frames_embedding_idx = np.where(np.isin(all_frame_idx,frames_eeg_idx))[0]\n",
    "            raw_embedding_chunk = d['embedding'][frames_embedding_idx]\n",
    "            embedding_chunk = signal.resample(raw_embedding_chunk,frames_len)\n",
    "            embedding_chunks.append(embedding_chunk)\n",
    "            pointer = end-overlap\n",
    "    # splitting #####################################################\n",
    "    sizes = np.dot(split, len(eeg_chunks))\n",
    "    sizes_ints = [int(sz) for sz in sizes]\n",
    "    test_inds = npr.choice(len(eeg_chunks), sizes_ints[1], replace=False)\n",
    "    train_inds = np.setdiff1d(np.arange(len(eeg_chunks)), test_inds)\n",
    "    npr.shuffle(train_inds)\n",
    "    # finalizing\n",
    "    train_eeg = np.stack(eeg_chunks)[train_inds]\n",
    "    test_eeg = np.stack(eeg_chunks)[test_inds]\n",
    "    train_embedding = np.stack(embedding_chunks)[train_inds]\n",
    "    test_embedding = np.stack(embedding_chunks)[test_inds]\n",
    "    return {'train': (train_eeg,train_embedding), 'test': (test_eeg,test_embedding)}\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:20<00:00,  6.69s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_data(data,200,3,overlap=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling\n",
    "with open('finWFT_300_3_o350_s60lf20hf80.pkl', 'wb') as pickle_out:  \n",
    "    pickle.dump(dataset, pickle_out,protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
